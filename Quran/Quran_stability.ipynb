{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "774b973a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hindi\n",
      "2518\n",
      "2548\n",
      "2590\n",
      "29\n",
      "401\n",
      "english\n",
      "2518\n",
      "2548\n",
      "2590\n",
      "29\n",
      "401\n",
      "bulgarian\n",
      "2518\n",
      "2548\n",
      "2590\n",
      "29\n",
      "401\n",
      "arabic\n",
      "2518\n",
      "2548\n",
      "2590\n",
      "29\n",
      "401\n"
     ]
    }
   ],
   "source": [
    "# Create five word2vec embedding spaces (with different random seeds) for each language of the quran.\n",
    "\n",
    "from collections import Counter\n",
    "from gensim.models import word2vec\n",
    "import sys\n",
    "import pickle\n",
    "import string\n",
    "\n",
    "# SET THESE VARIABLES\n",
    "\n",
    "# Location where the Quran text is stored\n",
    "quran_path='/Users/nehakardam/Project-CSE517/Quran/'\n",
    "\n",
    "# Location where output embedding spaces will be stored\n",
    "# Files will be stored in the format {output_path}{language}_{word2vec_seed}.pkl, where the pickle file is a pickled gensim word2vec model\n",
    "output_path = quran_path\n",
    "\n",
    "# List of word2vec seeds to use (can adjust if needed, or leave the same)\n",
    "seeds = [2518,2548,2590,29,401]\n",
    "\n",
    "# The following is a list of Quran translations that can be used to create embedding spaces for (can adjust if needed, or leave the same)\n",
    "# (The next line of code will remove the .txt ending from each language, so this list assumes that each language will have the .txt ending)\n",
    "languages=['hindi.txt', 'english.txt','bulgarian.txt', 'arabic.txt']\n",
    "languages=[i[:-4] for i in languages] #remove .txt\n",
    "\n",
    "# Create embeddings for each language\n",
    "for language in languages:\n",
    "    print(language)\n",
    "\n",
    "    # Create embeddings for each seed for that language\n",
    "    for seed in seeds:\n",
    "        print(seed)\n",
    "\n",
    "        # Read in quran text\n",
    "        with open(quran_path+language+'.txt','r') as text_file:\n",
    "            sentences = text_file.readlines()\n",
    "            sentences = [i[:-1].split(' ') for i in sentences]\n",
    "\n",
    "        # Create word2vec embedding space\n",
    "        model = word2vec.Word2Vec(sentences,window=5,min_count=5,seed=seed)\n",
    "\n",
    "        # Save model for future use\n",
    "        with open(output_path+language+'_'+str(seed)+'.pkl', 'wb') as pickle_file:\n",
    "            pickle.dump(model,pickle_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473c6a3c",
   "metadata": {},
   "source": [
    "# Below section precalculate the five nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b8ffa46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english\n",
      "2518\n",
      "Load model...\n",
      "Normalizing vectors\n",
      "d 99\n",
      "nb 31\n",
      "nq 31\n",
      "Creating query matrix...\n",
      "(31, 99)\n",
      "Building index...\n",
      "Calculating nearest neighbors...\n",
      "Recording nearest neighbors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 31/31 [00:00<00:00, 18596.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving nearest neighbors...\n",
      "2548\n",
      "Load model...\n",
      "Normalizing vectors\n",
      "d 99\n",
      "nb 31\n",
      "nq 31\n",
      "Creating query matrix...\n",
      "(31, 99)\n",
      "Building index...\n",
      "Calculating nearest neighbors...\n",
      "Recording nearest neighbors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 31/31 [00:00<00:00, 102300.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving nearest neighbors...\n",
      "2590\n",
      "Load model...\n",
      "Normalizing vectors\n",
      "d 99\n",
      "nb 31\n",
      "nq 31\n",
      "Creating query matrix...\n",
      "(31, 99)\n",
      "Building index...\n",
      "Calculating nearest neighbors...\n",
      "Recording nearest neighbors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 31/31 [00:00<00:00, 91759.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving nearest neighbors...\n",
      "29\n",
      "Load model...\n",
      "Normalizing vectors\n",
      "d 99\n",
      "nb 31\n",
      "nq 31\n",
      "Creating query matrix...\n",
      "(31, 99)\n",
      "Building index...\n",
      "Calculating nearest neighbors...\n",
      "Recording nearest neighbors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 31/31 [00:00<00:00, 111512.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving nearest neighbors...\n",
      "401\n",
      "Load model...\n",
      "Normalizing vectors\n",
      "d 99\n",
      "nb 31\n",
      "nq 31\n",
      "Creating query matrix...\n",
      "(31, 99)\n",
      "Building index...\n",
      "Calculating nearest neighbors...\n",
      "Recording nearest neighbors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 31/31 [00:00<00:00, 58385.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving nearest neighbors...\n",
      "arabic\n",
      "2518\n",
      "Load model...\n",
      "Normalizing vectors\n",
      "d 99\n",
      "nb 34\n",
      "nq 34\n",
      "Creating query matrix...\n",
      "(34, 99)\n",
      "Building index...\n",
      "Calculating nearest neighbors...\n",
      "Recording nearest neighbors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 34/34 [00:00<00:00, 64121.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving nearest neighbors...\n",
      "2548\n",
      "Load model...\n",
      "Normalizing vectors\n",
      "d 99\n",
      "nb 34\n",
      "nq 34\n",
      "Creating query matrix...\n",
      "(34, 99)\n",
      "Building index...\n",
      "Calculating nearest neighbors...\n",
      "Recording nearest neighbors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 34/34 [00:00<00:00, 71589.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving nearest neighbors...\n",
      "2590\n",
      "Load model...\n",
      "Normalizing vectors\n",
      "d 99\n",
      "nb 34\n",
      "nq 34\n",
      "Creating query matrix...\n",
      "(34, 99)\n",
      "Building index...\n",
      "Calculating nearest neighbors...\n",
      "Recording nearest neighbors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 34/34 [00:00<00:00, 95773.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving nearest neighbors...\n",
      "29\n",
      "Load model...\n",
      "Normalizing vectors\n",
      "d 99\n",
      "nb 34\n",
      "nq 34\n",
      "Creating query matrix...\n",
      "(34, 99)\n",
      "Building index...\n",
      "Calculating nearest neighbors...\n",
      "Recording nearest neighbors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 34/34 [00:00<00:00, 109697.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving nearest neighbors...\n",
      "401\n",
      "Load model...\n",
      "Normalizing vectors\n",
      "d 99\n",
      "nb 34\n",
      "nq 34\n",
      "Creating query matrix...\n",
      "(34, 99)\n",
      "Building index...\n",
      "Calculating nearest neighbors...\n",
      "Recording nearest neighbors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 34/34 [00:00<00:00, 98349.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving nearest neighbors...\n",
      "hindi\n",
      "2518\n",
      "Load model...\n",
      "Normalizing vectors\n",
      "d 99\n",
      "nb 31\n",
      "nq 31\n",
      "Creating query matrix...\n",
      "(31, 99)\n",
      "Building index...\n",
      "Calculating nearest neighbors...\n",
      "Recording nearest neighbors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 31/31 [00:00<00:00, 99634.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving nearest neighbors...\n",
      "2548\n",
      "Load model...\n",
      "Normalizing vectors\n",
      "d 99\n",
      "nb 31\n",
      "nq 31\n",
      "Creating query matrix...\n",
      "(31, 99)\n",
      "Building index...\n",
      "Calculating nearest neighbors...\n",
      "Recording nearest neighbors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 31/31 [00:00<00:00, 113557.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving nearest neighbors...\n",
      "2590\n",
      "Load model...\n",
      "Normalizing vectors\n",
      "d 99\n",
      "nb 31\n",
      "nq 31\n",
      "Creating query matrix...\n",
      "(31, 99)\n",
      "Building index...\n",
      "Calculating nearest neighbors...\n",
      "Recording nearest neighbors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 31/31 [00:00<00:00, 96313.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving nearest neighbors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "Load model...\n",
      "Normalizing vectors\n",
      "d 99\n",
      "nb 31\n",
      "nq 31\n",
      "Creating query matrix...\n",
      "(31, 99)\n",
      "Building index...\n",
      "Calculating nearest neighbors...\n",
      "Recording nearest neighbors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 31/31 [00:00<00:00, 105796.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving nearest neighbors...\n",
      "401\n",
      "Load model...\n",
      "Normalizing vectors\n",
      "d 99\n",
      "nb 31\n",
      "nq 31\n",
      "Creating query matrix...\n",
      "(31, 99)\n",
      "Building index...\n",
      "Calculating nearest neighbors...\n",
      "Recording nearest neighbors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 31/31 [00:00<00:00, 106839.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving nearest neighbors...\n",
      "bulgarian\n",
      "2518\n",
      "Load model...\n",
      "Normalizing vectors\n",
      "d 99\n",
      "nb 23\n",
      "nq 23\n",
      "Creating query matrix...\n",
      "(23, 99)\n",
      "Building index...\n",
      "Calculating nearest neighbors...\n",
      "Recording nearest neighbors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 23/23 [00:00<00:00, 83019.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving nearest neighbors...\n",
      "2548\n",
      "Load model...\n",
      "Normalizing vectors\n",
      "d 99\n",
      "nb 23\n",
      "nq 23\n",
      "Creating query matrix...\n",
      "(23, 99)\n",
      "Building index...\n",
      "Calculating nearest neighbors...\n",
      "Recording nearest neighbors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 23/23 [00:00<00:00, 89822.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving nearest neighbors...\n",
      "2590\n",
      "Load model...\n",
      "Normalizing vectors\n",
      "d 99\n",
      "nb 23\n",
      "nq 23\n",
      "Creating query matrix...\n",
      "(23, 99)\n",
      "Building index...\n",
      "Calculating nearest neighbors...\n",
      "Recording nearest neighbors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 23/23 [00:00<00:00, 95137.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving nearest neighbors...\n",
      "29\n",
      "Load model...\n",
      "Normalizing vectors\n",
      "d 99\n",
      "nb 23\n",
      "nq 23\n",
      "Creating query matrix...\n",
      "(23, 99)\n",
      "Building index...\n",
      "Calculating nearest neighbors...\n",
      "Recording nearest neighbors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 23/23 [00:00<00:00, 94949.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving nearest neighbors...\n",
      "401\n",
      "Load model...\n",
      "Normalizing vectors\n",
      "d 99\n",
      "nb 23\n",
      "nq 23\n",
      "Creating query matrix...\n",
      "(23, 99)\n",
      "Building index...\n",
      "Calculating nearest neighbors...\n",
      "Recording nearest neighbors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 23/23 [00:00<00:00, 77923.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving nearest neighbors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Precalculate the five nearest neighbors for every word for every language in the Quran.\n",
    "\n",
    "import faiss\n",
    "import time\n",
    "import tables as tb\n",
    "import pickle\n",
    "from sklearn.neighbors import BallTree\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from tqdm import tqdm,trange\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# SET THESE VARIABLES\n",
    "\n",
    "# Files should be stored in the format {quran_path}{language}_{word2vec_seed}.pkl, where the pickle file is a pickled gensim word2vec model\n",
    "quran_path = '/Users/nehakardam/Project-CSE517/Quran/'\n",
    "\n",
    "# Location where output nearest neighbors will be stored\n",
    "# Files will be stored in the format {output_path}{language}_{word2vec_seed}.pkl, where the pickle file is a dictionary where the keys are words and the values are lists of ten nearest neighbors for each word.\n",
    "output_path=quran_path+'nearestNeighbors/'\n",
    "\n",
    "# List of word2vec seeds to use (can adjust if needed, or leave the same)\n",
    "seeds = [2518,2548,2590,29,401]\n",
    "\n",
    "# List of quran translations (can adjust if needed, or leave the same)\n",
    "# (The next line of code will remove the .txt ending from each language, so this list assumes that each language will have the .txt ending)\n",
    "languages=['english.txt', 'arabic.txt','hindi.txt', 'bulgarian.txt']\n",
    "languages=[i[:-4] for i in languages] #remove .txt\n",
    "\n",
    "# Precalculate nearest neighbors for each language\n",
    "for language in languages:\n",
    "    print(language)\n",
    "\n",
    "    # Precalculate nearest neighbors for each seed for that language\n",
    "    for seed in seeds:\n",
    "        print(seed)\n",
    "\n",
    "       # Read in embedding space model\n",
    "        print('Load model...')\n",
    "        with open(quran_path+language+'_'+str(seed)+'.pkl','rb') as pickleFile:\n",
    "            model = pickle.load(pickleFile)\n",
    "        embedding_words = list(model.wv.index_to_key)\n",
    "        embeddings = [model.wv[word] for word in embedding_words]\n",
    "\n",
    "        xb = np.array([[float(j) for j in i[1:]] for i in embeddings],dtype='float32') #database\n",
    "\n",
    "        print('Normalizing vectors')\n",
    "        xb = normalize(xb)\n",
    "    # \t\tfor i in trange(len(xb)):\n",
    "    # \t\t\txb[i] = normalize(xb[i].reshape(-1, 1))\n",
    "\n",
    "        d = xb.shape[1] #dimension\n",
    "        nb = xb.shape[0] #database size\n",
    "        nq = len(embedding_words) #num queries\n",
    "        print('d',d)\n",
    "        print('nb',nb)\n",
    "        print('nq',nq)\n",
    "\n",
    "        print('Creating query matrix...')\n",
    "        xq = xb[[i for i in range(len(embedding_words))],:]\n",
    "        print(xq.shape)\n",
    "\n",
    "        print('Building index...')\n",
    "        faiss_index = faiss.IndexFlatL2(d)\n",
    "        faiss_index.add(xb) \n",
    "\n",
    "        k = 11 #number of nearest neighbors\n",
    "\n",
    "        print('Calculating nearest neighbors...')\n",
    "        D, I = faiss_index.search(xq, k)\n",
    "\n",
    "        nearestNeighbors = {}\n",
    "        print('Recording nearest neighbors...')\n",
    "        for i in tqdm(range(len(embedding_words))):\n",
    "            word = embedding_words[i]\n",
    "            nearestNeighbors[word] = [embedding_words[j] for j in I[i]][1:]\n",
    "\n",
    "        #Save final\n",
    "        print('Saving nearest neighbors...')\n",
    "        with open(output_path+language+'_'+str(seed)+'.pkl','wb') as pickleFile:\n",
    "            pickle.dump(nearestNeighbors,pickleFile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1437998c",
   "metadata": {},
   "source": [
    "# Stability for each language in the Quran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7bfb543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english\n",
      "Reading ten nearest neighbors...\n",
      "2518\n",
      "2548\n",
      "2590\n",
      "29\n",
      "401\n",
      "Calculating stabilities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 31/31 [00:00<00:00, 26908.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing output file...\n",
      "arabic\n",
      "Reading ten nearest neighbors...\n",
      "2518\n",
      "2548\n",
      "2590\n",
      "29\n",
      "401\n",
      "Calculating stabilities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 34/34 [00:00<00:00, 32783.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing output file...\n",
      "hindi\n",
      "Reading ten nearest neighbors...\n",
      "2518\n",
      "2548\n",
      "2590\n",
      "29\n",
      "401\n",
      "Calculating stabilities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 31/31 [00:00<00:00, 26513.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing output file...\n",
      "bulgarian\n",
      "Reading ten nearest neighbors...\n",
      "2518\n",
      "2548\n",
      "2590\n",
      "29\n",
      "401\n",
      "Calculating stabilities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 23/23 [00:00<00:00, 26143.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing output file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate stability for each language in the Quran.\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.neighbors import BallTree\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import sys\n",
    "from tqdm import tqdm,trange\n",
    "import pandas as pd\n",
    "\n",
    "# SET THESE VARIABLES\n",
    "\n",
    "# Files should be stored in the format {quran_path}{language}_{word2vec_seed}.pkl, where the pickle file is a dictionary where the keys are words and the values are lists of ten nearest neighbors for each word.\n",
    "quran_path = '/Users/nehakardam/Project-CSE517/Quran/nearestNeighbors/'\n",
    "\n",
    "# Location where output stability will be stored\n",
    "# Files will be stored in the format {output_path}{language}.csv, where the csv file has columns \"word\" and \"stability\", and the stability value is recorded for each word\n",
    "output_path = '/Users/nehakardam/Project-CSE517/Quran/stability/'\n",
    "\n",
    "# List of word2vec seeds to use (can adjust if needed, or leave the same)\n",
    "seeds = [2518,2548,2590,29,401]\n",
    "\n",
    "# List of quran translations (can adjust if needed, or leave the same)\n",
    "# (The next line of code will remove the .txt ending from each language, so this list assumes that each language will have the .txt ending)\n",
    "    \n",
    "languages=['english.txt', 'arabic.txt','hindi.txt', 'bulgarian.txt']\n",
    "languages=[i[:-4] for i in languages] #remove .txt\n",
    "\n",
    "# Calculates the stability of a word in two sets of embedding spaces\n",
    "# Assumes that you've already calculated the most similar words for the word\n",
    "#\n",
    "# @param word\n",
    "#    The word to calculate stability for\n",
    "# @param similar1\n",
    "#    The list of nearest neighbors to word in the first set of embedding spaces\n",
    "#    len(similar1) = # of embedding spaces in the first set\n",
    "#    For each i, len(similar1[i]) = # of nearest neighbors to consider (same for each i)\n",
    "# @param similar2\n",
    "#    The list of nearest neighbors to word in the second set of embedding spaces\n",
    "# @param same\n",
    "#    Are the two lists of embedding spaces the same? (default = False)\n",
    "#\n",
    "# @returns a float, the average stability of the word across the two sets of spaces\n",
    "#\n",
    "def stability(word,similar1,similar2,same=False):\n",
    "    if same and len(similar1) == 1:\n",
    "        return len(similar1[0])\n",
    "    \n",
    "    sets1 = [set(a) for a in similar1]\n",
    "    if not same:\n",
    "        sets2 = [set(b) for b in similar2]\n",
    "    else:\n",
    "        sets2 = sets1\n",
    "    \n",
    "    avgOverlap = 0\n",
    "    for i in range(len(similar1)):\n",
    "        for j in range(len(similar2)):\n",
    "            if not same or (same and i!=j):\n",
    "                avgOverlap += len(sets1[i] & sets2[j])\n",
    "\n",
    "    if same:\n",
    "        avgOverlap /= (len(similar1)*len(similar2)-len(similar1))\n",
    "    else:\n",
    "        avgOverlap /= (len(similar1)*len(similar2))\n",
    "    return avgOverlap\n",
    "\n",
    "# Calculate stability for each language\n",
    "for language in languages:\n",
    "    print(language)\n",
    "\n",
    "    print('Reading ten nearest neighbors...')\n",
    "    nearest_neighbors = []\n",
    "    words = set()\n",
    "    for seed in seeds:\n",
    "        print(seed)\n",
    "        with open(quran_path+language+'_'+str(seed)+'.pkl','rb') as pickleFile:\n",
    "            nearest_neighbors.append(pickle.load(pickleFile))\n",
    "            _words = set(nearest_neighbors[-1].keys())\n",
    "            if len(words)==0:\n",
    "                words = _words\n",
    "            else:\n",
    "                words = words.intersection(_words)\n",
    "    words = list(words)\n",
    "\n",
    "    print('Calculating stabilities...')\n",
    "    stabilities = []\n",
    "    for word in tqdm(words):\n",
    "        most_similar = []\n",
    "        for i in range(5):\n",
    "            most_similar.append(nearest_neighbors[i][word])\n",
    "        stabilities.append(stability(word,most_similar,most_similar,True))\n",
    "\n",
    "    print('Writing output file...')\n",
    "    df = pd.DataFrame(data={'word':words,'stability':stabilities})\n",
    "    df.to_csv(output_path+language+'.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
