{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laura Burdick (lburdick@umich.edu)\n",
    "# Filter WALS values and languages for final regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET THESE VARIABLES\n",
    "\n",
    "# Location of binary WALS path (created with Making Wals Binary.ipynb)\n",
    "# Should be formatted as a csv file, with a separate column for each\n",
    "# binary WALS value, as well as a column called \"language\" with the\n",
    "# Bible language codes\n",
    "binary_wals_path = '../corpus/wals/wals_bible_binary_values.csv'\n",
    "\n",
    "# Location of output WALS labels for final regression model\n",
    "# Formatted as a pickle file which contains a list of WALS values\n",
    "wals_label_path = '../corpus/wals/allLanguages_wals_values.pkl'\n",
    "\n",
    "# Location of output WALS features for each language for regression model\n",
    "# For each language, formatted as a pickle file with name\n",
    "# {wals_features_path}{language}.pkl, where pickle file contains a list\n",
    "# of WALS feature values for that language\n",
    "wals_features_path = '../corpus/wals/allLanguages_language_features_small_wals_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all languages in either Wikipedia or the Bible\n",
    "all_languages = ['afr', 'aln', 'arb', 'arz', 'ayr', 'azb', 'azj', 'bba', 'ben', 'bqc', 'bul', 'cac', 'cak', 'ceb',\\\n",
    "                 'ces', 'che', 'cme', 'cmn', 'cnh', 'crh', 'cym', 'dan', 'deu', 'dyu', 'ell', 'eng', 'epo', 'fin',\\\n",
    "                 'fra', 'gub', 'guj', 'gur', 'hat', 'hmo', 'hrv', 'hui', 'hun', 'ifa', 'ifb', 'ify', 'ind', 'ita',\\\n",
    "                 'kac', 'kaz', 'kek', 'kjb', 'kor', 'lat', 'lit', 'lnd', 'lsi', 'mad', 'mah', 'mam', 'may', 'mdy',\\\n",
    "                 'mlg', 'mps', 'mri', 'mrw', 'mya', 'nhe', 'nld', 'nor', 'pis', 'plt', 'poh', 'por', 'prs', 'pxm',\\\n",
    "                 'qub', 'quh', 'quy', 'quz', 'qxr', 'ron', 'rug', 'rus', 'som', 'suz', 'swe', 'tat', 'tbz', 'tcw',\\\n",
    "                 'tgl', 'tlh', 'tpi', 'tpm', 'tur', 'tzo', 'ukr', 'vie', 'wal', 'wbm', 'xho', 'yua', 'zom', 'cat',\\\n",
    "                 'spa', 'est', 'fas', 'heb', 'hin', 'jpn', 'lav', 'pol', 'slk', 'slv', 'srp', 'tha','mnd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wals = pd.read_csv(binary_wals_path)\n",
    "wals = wals.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all WALS properties\n",
    "wals_numbers = list(set([i.split(':')[0] for i in wals.columns.values][:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of unknown WALS properties for each language\n",
    "all_unknown = []\n",
    "for language in all_languages:\n",
    "    unknown = 0\n",
    "    for number in wals_numbers:\n",
    "        relevant_columns = [i for i in wals.columns.values[:-1] if i.split(':')[0]==number]\n",
    "        null_column = [i for i in relevant_columns if i.split('__')[-1]==''][0]\n",
    "        if list(wals.loc[wals.language==language][null_column])[0]==1:\n",
    "            unknown += 1\n",
    "    all_unknown.append(copy.copy(unknown)/len(wals_numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sorted by number of unknown WALS properties per langugage\n",
    "(all_unknown,languages_sorted)=zip(*sorted(zip(all_unknown,all_languages)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eng', 'rus', 'fin', 'hun', 'spa', 'ind', 'mnd', 'tur', 'jpn', 'kor', 'prs', 'hin', 'vie', 'heb', 'may', 'tha', 'lav', 'lat', 'hmo', 'cmn', 'pol', 'som', 'bul', 'ita', 'lit', 'swe', 'hat', 'nor', 'poh', 'est', 'mam', 'por', 'ukr', 'ben', 'che', 'lnd', 'mad']\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "# Only include languages that have at least 25% of all WALS properties\n",
    "all_languages = [languages_sorted[i] for i in range(len(languages_sorted)) if all_unknown[i]<0.75]\n",
    "print(all_languages)\n",
    "print(len(all_languages)) # Should have 37 languages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in mapping between Bible language names and Wikipedia language names\n",
    "language_mapping = pd.read_csv('multilingual_corpora.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English\n",
      "Russian\n",
      "Finnish\n",
      "Hungarian\n",
      "Spanish\n",
      "Indonesian\n",
      "Turkish\n",
      "Japanese\n",
      "Korean\n",
      "Hindi\n",
      "Vietnamese\n",
      "Hebrew\n",
      "Thai\n",
      "Latvian\n",
      "Latin\n",
      "Polish\n",
      "Somali\n",
      "Bulgarian\n",
      "Italian\n",
      "Lithuanian\n",
      "Swedish\n",
      "Haitian, Haitian Creole\n",
      "Norwegian\n",
      "Estonian\n",
      "Mam\n",
      "Portuguese\n",
      "Ukrainian\n"
     ]
    }
   ],
   "source": [
    "# Get full language name for each language\n",
    "long_languages = []\n",
    "for language in all_languages:\n",
    "    _df = language_mapping.loc[language_mapping['ISO 639-3 Code']==language]\n",
    "    if len(_df) >= 1:\n",
    "        print(list(_df['Language'])[0])\n",
    "        long_languages.append(list(_df['Language'])[0])\n",
    "    else:\n",
    "        if language == 'mnd': # Some additional manual mappings\n",
    "            long_languages.append('Mandarin')\n",
    "        elif language == 'prs':\n",
    "            long_languages.append('Persian')\n",
    "        elif language == 'may':\n",
    "            long_languages.append('Maybrat')\n",
    "        elif language == 'hmo':\n",
    "            long_languages.append('Hmong Njua')\n",
    "        elif language=='cmn':\n",
    "            long_languages.append('Comanche')\n",
    "        elif language=='poh':\n",
    "            long_languages.append('Pohnpeian')\n",
    "        elif language=='ben':\n",
    "            long_languages.append('Bengali')\n",
    "        elif language=='che':\n",
    "            long_languages.append('Cherokee')\n",
    "        elif language=='lnd':\n",
    "            long_languages.append('Linda')\n",
    "        elif language=='mad':\n",
    "            long_languages.append(\"Ma'di\")\n",
    "        else:\n",
    "            print(language,'not in language mapping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only take subset of WALS dataset for languages that we need\n",
    "wals = wals.loc[wals.language.isin(all_languages)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only consider WALS properties where at list 25% of filtered languages\n",
    "# have the property, and at least 5 languages have the property\n",
    "good_wals = []\n",
    "good_wals_columns = []\n",
    "ratios = []\n",
    "for number in wals_numbers:\n",
    "    relevant_columns = [i for i in wals.columns.values[:-1] if i.split(':')[0]==number]\n",
    "    null_column = [i for i in relevant_columns if i.split('__')[-1]==''][0]\n",
    "    relevant_columns = [i for i in relevant_columns if i != null_column]\n",
    "    null_column_count = wals[null_column].sum()\n",
    "    ratio = null_column_count / len(all_languages) #percent of languages that don't have this property\n",
    "    ratios.append(ratio)\n",
    "    if ratio > 0.75:\n",
    "        continue #Greater than 75% of languages don't have this property\n",
    "    \n",
    "    good_columns = []\n",
    "    for column in relevant_columns:\n",
    "        column_count = wals[column].sum()\n",
    "        if column_count >= 5: #At least 5 languages have this property\n",
    "            good_columns.append(column)\n",
    "            \n",
    "    if len(good_columns) < 2: #There aren't two non-unknown features with greater than 5 languages\n",
    "        continue\n",
    "        \n",
    "    good_wals.append(number)\n",
    "    good_wals_columns += good_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5388888888888889"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good_wals)/len(ratios) #percentage of wals properties that we're keeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good_wals) # Should be 97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Spearman's correlations between all WALS properties\n",
    "# (Includes manually grouped sets of properties)\n",
    "correlations = pd.read_csv('correlations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correlations_mapping1 = {} #mapping from WALS property to correlation group\n",
    "correlations_mapping2 = {} #mapping from correlation group to WALS property\n",
    "for it,row in correlations.iterrows():\n",
    "    correlations_mapping1[row.property1] = row.groupNum\n",
    "    correlations_mapping1[row.property2] = row.groupNum\n",
    "    if row.groupNum not in correlations_mapping2:\n",
    "        correlations_mapping2[row.groupNum] = set()\n",
    "    correlations_mapping2[row.groupNum].add(row.property1)\n",
    "    correlations_mapping2[row.groupNum].add(row.property2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace correlated WALS properties with their correlation group\n",
    "all_languages_wals_values = [i for i in wals.columns.values if \\\n",
    "                             i in good_wals_columns]\n",
    "all_languages_wals_values = [i if i not in correlations_mapping1 \\\n",
    "                             else 'correlations_'+\\\n",
    "                             str(correlations_mapping1[i])\\\n",
    "                             for i in all_languages_wals_values ]\n",
    "all_languages_wals_values = list(set(all_languages_wals_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['65A: Perfective/Imperfective Aspect__2.0', '98A: Alignment of Case Marking of Full Noun Phrases__1.0', '101A: Expression of Pronominal Subjects__1.0', '110A: Periphrastic Causative Constructions__1.0', '74A: Situational Possibility__2.0', '29A: Syncretism in Verbal Person/Number Marking__3.0', '21A: Exponence of Selected Inflectional Formatives__5.0', '117A: Predicative Possession__1.0', '72A: Imperative-Hortative Systems__4.0', '3A: Consonant-Vowel Ratio__2.0', '100A: Alignment of Verbal Person Marking__2.0', '101A: Expression of Pronominal Subjects__2.0', '72A: Imperative-Hortative Systems__1.0', '64A: Nominal and Verbal Conjunction__2.0', '120A: Zero Copula for Predicate Nominals__2.0', '129A: Hand and Arm__2.0', '51A: Position of Case Affixes__1.0', '106A: Reciprocal Constructions__3.0', '92A: Position of Polar Question Particles__1.0', '54A: Distributive Numerals__1.0', '69A: Position of Tense-Aspect Affixes__5.0', '122A: Relativization on Subjects__1.0', '113A: Symmetric and Asymmetric Standard Negation__3.0', '97A: Relationship between the Order of Object and Verb and the Order of Adjective and Noun__3.0', '112A: Negative Morphemes__1.0', '85A: Order of Adposition and Noun Phrase__1.0', '87A: Order of Adjective and Noun__1.0', '76A: Overlap between Situational and Epistemic Modal Marking__1.0', '90A: Order of Relative Clause and Noun__2.0', '38A: Indefinite Articles__5.0', '32A: Systems of Gender Assignment__3.0', '44A: Gender Distinctions in Independent Personal Pronouns__6.0', '71A: The Prohibitive__1.0', '118A: Predicative Adjectives__1.0', '114A: Subtypes of Asymmetric Standard Negation__3.0', '125A: Purpose Clauses__3.0', '74A: Situational Possibility__1.0', '102A: Verbal Person Marking__1.0', '55A: Numeral Classifiers__1.0', '57A: Position of Pronominal Possessive Affixes__4.0', '36A: The Associative Plural__4.0', '123A: Relativization on Obliques__1.0', '65A: Perfective/Imperfective Aspect__1.0', '88A: Order of Demonstrative and Noun__2.0', '144A: Position of Negative Word With Respect to Subject, Object, and Verb__2.0', '78A: Coding of Evidentiality__1.0', '46A: Indefinite Pronouns__1.0', '127A: Reason Clauses__2.0', '47A: Intensifiers and Reflexive Pronouns__2.0', '5A: Voicing and Gaps in Plosive Systems__1.0', '38A: Indefinite Articles__1.0', '143F: Postverbal Negative Morphemes__4.0', '12A: Syllable Structure__2.0', '27A: Reduplication__1.0', '41A: Distance Contrasts in Demonstratives__2.0', '119A: Nominal and Locational Predication__2.0', '95A: Relationship between the Order of Object and Verb and the Order of Adposition and Noun Phrase__4.0', '121A: Comparative Constructions__4.0', '38A: Indefinite Articles__2.0', '112A: Negative Morphemes__2.0', '142A: Para-Linguistic Usages of Clicks__2.0', '4A: Voicing in Plosives and Fricatives__2.0', '52A: Comitatives and Instrumentals__1.0', '117A: Predicative Possession__5.0', '67A: The Future Tense__2.0', '69A: Position of Tense-Aspect Affixes__2.0', '144A: Position of Negative Word With Respect to Subject, Object, and Verb__20.0', '37A: Definite Articles__4.0', '44A: Gender Distinctions in Independent Personal Pronouns__3.0', '55A: Numeral Classifiers__2.0', '98A: Alignment of Case Marking of Full Noun Phrases__2.0', '13A: Tone__1.0', '138A: Tea__2.0', '89A: Order of Numeral and Noun__1.0', '53A: Ordinal Numerals__5.0', '29A: Syncretism in Verbal Person/Number Marking__1.0', '55A: Numeral Classifiers__3.0', '70A: The Morphological Imperative__5.0', '90A: Order of Relative Clause and Noun__1.0', '17A: Rhythm Types__1.0', '26A: Prefixing vs. Suffixing in Inflectional Morphology__2.0', '68A: The Perfect__4.0', '75A: Epistemic Possibility__1.0', '92A: Position of Polar Question Particles__2.0', '49A: Number of Cases__1.0', '100A: Alignment of Verbal Person Marking__1.0', '110A: Periphrastic Causative Constructions__2.0', '70A: The Morphological Imperative__1.0', '125A: Purpose Clauses__1.0', '68A: The Perfect__3.0', '57A: Position of Pronominal Possessive Affixes__2.0', '81A: Order of Subject, Object and Verb__2.0', '2A: Vowel Quality Inventories__3.0', '102A: Verbal Person Marking__2.0', '77A: Semantic Distinctions of Evidentiality__1.0', '4A: Voicing in Plosives and Fricatives__4.0', '136B: M in First Person Singular__2.0', '82A: Order of Subject and Verb__3.0', '92A: Position of Polar Question Particles__3.0', '81A: Order of Subject, Object and Verb__1.0', '16A: Weight Factors in Weight-Sensitive Stress Systems__1.0', '99A: Alignment of Case Marking of Pronouns__2.0', '4A: Voicing in Plosives and Fricatives__1.0', '17A: Rhythm Types__5.0', '52A: Comitatives and Instrumentals__2.0', \"124A: 'Want' Complement Subjects__1.0\", '118A: Predicative Adjectives__3.0', '120A: Zero Copula for Predicate Nominals__1.0', '118A: Predicative Adjectives__2.0', '14A: Fixed Stress Locations__2.0', '88A: Order of Demonstrative and Noun__1.0', '45A: Politeness Distinctions in Pronouns__1.0', '121A: Comparative Constructions__1.0', '78A: Coding of Evidentiality__2.0', '83A: Order of Object and Verb__2.0', '40A: Inclusive/Exclusive Distinction in Verbal Inflection__1.0', '50A: Asymmetrical Case-Marking__2.0', '5A: Voicing and Gaps in Plosive Systems__2.0', '31A: Sex-based and Non-sex-based Gender Systems__1.0', '21A: Exponence of Selected Inflectional Formatives__1.0', '27A: Reduplication__3.0', '97A: Relationship between the Order of Object and Verb and the Order of Adjective and Noun__1.0', '3A: Consonant-Vowel Ratio__1.0', '101A: Expression of Pronominal Subjects__5.0', '86A: Order of Genitive and Noun__2.0', '37A: Definite Articles__1.0', '22A: Inflectional Synthesis of the Verb__3.0', '83A: Order of Object and Verb__1.0', '2A: Vowel Quality Inventories__2.0', '103A: Third Person Zero of Verbal Person Marking__2.0', '29A: Syncretism in Verbal Person/Number Marking__2.0', '119A: Nominal and Locational Predication__1.0', '46A: Indefinite Pronouns__2.0', '136A: M-T Pronouns__2.0', '143E: Preverbal Negative Morphemes__1.0', '28A: Case Syncretism__1.0', '87A: Order of Adjective and Noun__2.0', '9A: The Velar Nasal__3.0', '51A: Position of Case Affixes__9.0', '114A: Subtypes of Asymmetric Standard Negation__7.0', \"126A: 'When' Clauses__1.0\", '92A: Position of Polar Question Particles__6.0', '16A: Weight Factors in Weight-Sensitive Stress Systems__6.0', '26A: Prefixing vs. Suffixing in Inflectional Morphology__1.0', '136A: M-T Pronouns__1.0', '32A: Systems of Gender Assignment__1.0', '36A: The Associative Plural__1.0', '123A: Relativization on Obliques__4.0', '13A: Tone__2.0', '38A: Indefinite Articles__4.0', '69A: Position of Tense-Aspect Affixes__4.0', '127A: Reason Clauses__1.0', '86A: Order of Genitive and Noun__1.0', '103A: Third Person Zero of Verbal Person Marking__4.0', '85A: Order of Adposition and Noun Phrase__2.0', '50A: Asymmetrical Case-Marking__3.0', '115A: Negative Indefinite Pronouns and Predicate Negation__3.0', '49A: Number of Cases__6.0', '9A: The Velar Nasal__2.0', '37A: Definite Articles__5.0', '22A: Inflectional Synthesis of the Verb__2.0', '31A: Sex-based and Non-sex-based Gender Systems__2.0', '138A: Tea__1.0', '30A: Number of Genders__2.0', '129A: Hand and Arm__1.0', '50A: Asymmetrical Case-Marking__1.0', '79A: Suppletion According to Tense and Aspect__4.0', '136B: M in First Person Singular__1.0', '14A: Fixed Stress Locations__1.0', '66A: The Past Tense__4.0', '41A: Distance Contrasts in Demonstratives__3.0', '79A: Suppletion According to Tense and Aspect__3.0', '86A: Order of Genitive and Noun__3.0', '115A: Negative Indefinite Pronouns and Predicate Negation__1.0', '93A: Position of Interrogative Phrases in Content Questions__2.0', '12A: Syllable Structure__3.0', '23A: Locus of Marking in the Clause__4.0', '143F: Postverbal Negative Morphemes__1.0', '40A: Inclusive/Exclusive Distinction in Verbal Inflection__3.0', '82A: Order of Subject and Verb__1.0', '25A: Locus of Marking: Whole-language Typology__5.0', '103A: Third Person Zero of Verbal Person Marking__1.0', '75A: Epistemic Possibility__3.0', \"126A: 'When' Clauses__2.0\", '89A: Order of Numeral and Noun__2.0', '76A: Overlap between Situational and Epistemic Modal Marking__2.0', '99A: Alignment of Case Marking of Pronouns__1.0', '102A: Verbal Person Marking__5.0', '77A: Semantic Distinctions of Evidentiality__2.0', '143E: Preverbal Negative Morphemes__4.0', '93A: Position of Interrogative Phrases in Content Questions__1.0', '53A: Ordinal Numerals__7.0', '142A: Para-Linguistic Usages of Clicks__1.0', '64A: Nominal and Verbal Conjunction__1.0', '125A: Purpose Clauses__2.0', '106A: Reciprocal Constructions__2.0', '45A: Politeness Distinctions in Pronouns__2.0', \"124A: 'Want' Complement Subjects__2.0\", '113A: Symmetric and Asymmetric Standard Negation__1.0', '71A: The Prohibitive__2.0', '122A: Relativization on Subjects__4.0', '144A: Position of Negative Word With Respect to Subject, Object, and Verb__16.0', '3A: Consonant-Vowel Ratio__3.0', '57A: Position of Pronominal Possessive Affixes__1.0', '23A: Locus of Marking in the Clause__2.0', '79A: Suppletion According to Tense and Aspect__1.0', '30A: Number of Genders__1.0', '95A: Relationship between the Order of Object and Verb and the Order of Adposition and Noun Phrase__1.0', '45A: Politeness Distinctions in Pronouns__4.0', '66A: The Past Tense__1.0', '26A: Prefixing vs. Suffixing in Inflectional Morphology__3.0', '54A: Distributive Numerals__5.0', '47A: Intensifiers and Reflexive Pronouns__1.0', '25A: Locus of Marking: Whole-language Typology__2.0', '67A: The Future Tense__1.0', '97A: Relationship between the Order of Object and Verb and the Order of Adjective and Noun__4.0', '28A: Case Syncretism__3.0']\n",
      "217\n"
     ]
    }
   ],
   "source": [
    "# Final list of WALS properties to use in the regression model\n",
    "print(all_languages_wals_values)\n",
    "print(len(all_languages_wals_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final list of WALS labels for regression model\n",
    "with open(wals_label_path,'wb') as pickleFile:\n",
    "    pickle.dump(all_languages_wals_values,pickleFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For each language, generate list of binary features for regression model.\n",
    "# Save list of binary features\n",
    "for language in all_languages:\n",
    "    language_wals = wals.loc[wals.language==language]\n",
    "    if len(language_wals) < 1:\n",
    "        print('ERROR: no wals information for language '+language)\n",
    "        continue\n",
    "    for it,row in language_wals.iterrows(): \n",
    "        language_wals_array = []\n",
    "        for wals_property in all_languages_wals_values:\n",
    "            \n",
    "            if wals_property[:13] == 'correlations_': #handle correlation groups\n",
    "                correlation_num = int(wals_property.split('_')[1])\n",
    "                relevant_columns = correlations_mapping2[correlation_num]\n",
    "                found = False\n",
    "                for column in list(relevant_columns): #if any of the correlation categories are 1, make it 1\n",
    "                    if row[column] == 1:\n",
    "                        found = True\n",
    "                        break\n",
    "                if found: #one of the columns had a 1 value\n",
    "                    language_wals_array.append(1)\n",
    "                else: #none of the columns had a 1 value\n",
    "                    language_wals_array.append(0)\n",
    "                continue\n",
    "                \n",
    "            #not a correlation group\n",
    "            language_wals_array.append(row[wals_property])\n",
    "                    \n",
    "        break #take only first row (only one row per language)\n",
    "        \n",
    "    # Save features for this language\n",
    "    with open(wals_features_path+language+'.pkl','wb') as pickleFile:\n",
    "        pickle.dump(language_wals_array,pickleFile) #WALS features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'5A: Voicing and Gaps in Plosive Systems__None missing in /p t k b d g/', '4A: Voicing in Plosives and Fricatives__In both plosives and fricatives'}\n",
      "\n",
      "\n",
      "1 {'32A: Systems of Gender Assignment__No gender', '31A: Sex-based and Non-sex-based Gender Systems__No gender', '44A: Gender Distinctions in Independent Personal Pronouns__No gender distinctions', '30A: Number of Genders__None'}\n",
      "\n",
      "\n",
      "2 {'32A: Systems of Gender Assignment__Semantic and formal', '31A: Sex-based and Non-sex-based Gender Systems__Sex-based'}\n",
      "\n",
      "\n",
      "3 {'37A: Definite Articles__No definite or indefinite article', '38A: Indefinite Articles__No definite or indefinite article'}\n",
      "\n",
      "\n",
      "4 {'102A: Verbal Person Marking__No person marking', '101A: Expression of Pronominal Subjects__Optional pronouns in subject position', '40A: Inclusive/Exclusive Distinction in Verbal Inflection__No person marking', '100A: Alignment of Verbal Person Marking__Neutral', '103A: Third Person Zero of Verbal Person Marking__No person marking', '29A: Syncretism in Verbal Person/Number Marking__No subject person/number marking'}\n",
      "\n",
      "\n",
      "5 {'50A: Asymmetrical Case-Marking__No case-marking', '99A: Alignment of Case Marking of Pronouns__Neutral', '66A: The Past Tense__No past tense', '98A: Alignment of Case Marking of Full Noun Phrases__Neutral'}\n",
      "\n",
      "\n",
      "6 {'26A: Prefixing vs. Suffixing in Inflectional Morphology__Strongly suffixing', '69A: Position of Tense-Aspect Affixes__Tense-aspect suffixes'}\n",
      "\n",
      "\n",
      "7 {'69A: Position of Tense-Aspect Affixes__No tense-aspect inflection', '23A: Locus of Marking in the Clause__No marking'}\n",
      "\n",
      "\n",
      "8 {'78A: Coding of Evidentiality__Verbal affix or clitic', '77A: Semantic Distinctions of Evidentiality__Indirect only'}\n",
      "\n",
      "\n",
      "9 {'78A: Coding of Evidentiality__No grammatical evidentials', '77A: Semantic Distinctions of Evidentiality__No grammatical evidentials'}\n",
      "\n",
      "\n",
      "10 {'83A: Order of Object and Verb__OV', '81A: Order of Subject, Object and Verb__SOV'}\n",
      "\n",
      "\n",
      "11 {'83A: Order of Object and Verb__VO', '81A: Order of Subject, Object and Verb__SVO'}\n",
      "\n",
      "\n",
      "12 {'95A: Relationship between the Order of Object and Verb and the Order of Adposition and Noun Phrase__VO and Prepositions', '85A: Order of Adposition and Noun Phrase__Prepositions'}\n",
      "\n",
      "\n",
      "13 {'97A: Relationship between the Order of Object and Verb and the Order of Adjective and Noun__OV and AdjN', '95A: Relationship between the Order of Object and Verb and the Order of Adposition and Noun Phrase__OV and Postpositions'}\n",
      "\n",
      "\n",
      "14 {'98A: Alignment of Case Marking of Full Noun Phrases__Nominative - accusative (standard)', '99A: Alignment of Case Marking of Pronouns__Nominative - accusative (standard)'}\n",
      "\n",
      "\n",
      "15 {'114A: Subtypes of Asymmetric Standard Negation__Non-assignable', '113A: Symmetric and Asymmetric Standard Negation__Symmetric'}\n",
      "\n",
      "\n",
      "16 {'118A: Predicative Adjectives__Nonverbal encoding', '119A: Nominal and Locational Predication__Identical'}\n",
      "\n",
      "\n",
      "17 {'122A: Relativization on Subjects__Gap', '136B: M in First Person Singular__No m in first person singular', '28A: Case Syncretism__No case marking', '136A: M-T Pronouns__No M-T pronouns'}\n",
      "\n",
      "\n",
      "18 {'122A: Relativization on Subjects__Relative pronoun', '123A: Relativization on Obliques__Relative pronoun'}\n",
      "\n",
      "\n",
      "19 {\"126A: 'When' Clauses__Balanced\", '127A: Reason Clauses__Balanced'}\n",
      "\n",
      "\n",
      "20 {'144A: Position of Negative Word With Respect to Subject, Object, and Verb__MorphNeg', '112A: Negative Morphemes__Negative affix'}\n",
      "\n",
      "\n",
      "21 {'136A: M-T Pronouns__M-T pronouns, paradigmatic', '136B: M in First Person Singular__m in first person singular'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here are all the correlation groupings\n",
    "for i in range(22):\n",
    "    print(i,correlations_mapping2[i])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
